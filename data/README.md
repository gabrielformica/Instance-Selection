Data sets for this problem are currently reduced to problem with numeric domains and with only one target variable. The variable to predict (the target) is the last element of every instance.

Datasets are considered of small, medium or large size given the number of instances they have as follows:
    * Small: 10-1000
    * Medium: 1001-10000
    * Large: More than 10001

Instances order in appearance are shuffled so it doesn't affect the partition of the datasets of the initial solution of the algorithm.

Studies regarding whether data should be normalized or not for any given dataset are in progress.



